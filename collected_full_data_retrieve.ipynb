{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "#First is HBS\n",
    "\n",
    "source='https://www.hbs.edu/coursecatalog/indexcourse.html'\n",
    "\n",
    "html = urlopen(str(source))\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tdlist = soup.find_all('td')\n",
    "\n",
    "reflist = []\n",
    "for i in range(len(tdlist)):\n",
    "    if str(tdlist[i])[:27] == '<td><a href=\"/coursecatalog':\n",
    "        reflist.append(str(tdlist[i]))\n",
    "    \n",
    "#This code is necessary because HBS has course descriptions on different pages, rather than collected in one URL.\n",
    "\n",
    "linklist = []\n",
    "for i in range(len(reflist)):\n",
    "    linklist.append(reflist[i][14:37])\n",
    "    \n",
    "#Creating a list of link extensions    \n",
    "    \n",
    "descraw = []\n",
    "\n",
    "for i in range(len(linklist)):\n",
    "    link = urlopen('https://www.hbs.edu/'+ linklist[i])\n",
    "    descsoup = BeautifulSoup(link, 'html.parser')\n",
    "    descraw.append(descsoup.findAll('p'))\n",
    "    \n",
    "#navigating to link extensions and retrieving course descriptions    \n",
    "\n",
    "\n",
    "titlelist = []\n",
    "for i in range(len(reflist)):\n",
    "    titlelist.append(re.sub('<[^<]+?>', '', str(reflist[i]))) \n",
    "#titlelist\n",
    "\n",
    "\n",
    "hbsdf = pd.DataFrame(titlelist, columns=[\"Course\"])\n",
    "hbsdf['Description'] = descraw\n",
    "\n",
    "hbsdf['Source'] = source\n",
    "\n",
    "for i in range(len(hbsdf)):\n",
    "    if i >0:\n",
    "        hbsdf['Source'][i]= ''\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "#This writes everything to a dataframe. Easy to export to excel. The original data is stored in a list, so it could\n",
    "#easily be written to a different kind of object, but I have used dataframes here for convenience.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is Wharton. This was the first code that I wrote, so it is a bit clunkier. Also, this includes prerequisites.\n",
    "#I have decided to remove this from the final version, because it is outside the scope of the original project.\n",
    "\n",
    "source='https://mgmt.wharton.upenn.edu/programs/mba/course-descriptions/'\n",
    "\n",
    "html = urlopen(str(source))\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "full_text = soup.get_text()\n",
    "\n",
    "title = soup.select('h3')\n",
    "para = soup.select('p')\n",
    "\n",
    "for i in range(len(title)):\n",
    "    title[i] = re.sub('<[^<]+?>', '', str(title[i]))\n",
    "\n",
    "#you can see here I am scrubbing everything unnecessarily early in the process. \n",
    "\n",
    "title1df = pd.DataFrame(title, columns=['Course'])\n",
    "\n",
    "title1df['Source'] = source\n",
    "\n",
    "#The above two sections are taking the raw course catalog and putting it into a dataframe. The below sections are removing the\n",
    "#'prerequisites' columns. Because this comes from the original code, where I created an excel file with only course names, \n",
    "#there is some redundancy here. Keeping it in case the code comes in handy later. \n",
    "\n",
    "for i in range(len(title1df)):\n",
    "    if i >0:\n",
    "        title1df['Source'][i]= ''\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "prereq = []\n",
    "\n",
    "for strong_tag in soup.find_all('strong'):\n",
    "    prereq.append((strong_tag.text, strong_tag.next_sibling))\n",
    "    \n",
    "poplist = []\n",
    "prereqlist = []\n",
    "\n",
    "for i in range(len(para)):\n",
    "    if str(para[i])[:11] == '<p><strong>':\n",
    "        poplist.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "newpara = []\n",
    "\n",
    "for i in range(len(para)):\n",
    "    if i in poplist:\n",
    "        prereqlist.append(para[i])\n",
    "    else:\n",
    "        newpara.append(para[i])\n",
    "\n",
    "        \n",
    "#All of this is to fix the problem of classes without prerequisites. This is redundant, but the code is included here in \n",
    "#case it is useful for another school's formatting (all these websites have different formatting)\n",
    "\n",
    "fulldf = pd.DataFrame(title[:-3], columns= ['Course'])\n",
    "\n",
    "fulldf['Source'] = source\n",
    "\n",
    "for i in range(len(fulldf)):\n",
    "    if i >0:\n",
    "        fulldf['Source'][i]= ''\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "fulldf['Description'] = ''\n",
    "\n",
    "for i in range(len(newpara)):\n",
    "    fulldf['Description'][i]= re.sub('<[^<]+?>', '', str(newpara[i]))\n",
    "\n",
    "newpara\n",
    "fulldf['Prerequisites'] = \"\"       \n",
    "\n",
    "for i in range(len(fulldf)):\n",
    "    for j in range(len(poplist)):\n",
    "        if i == poplist[j]:\n",
    "            fulldf['Prerequisites'][i]= re.sub('<[^<]+?>', '', str(prereqlist[j]))\n",
    "        else: continue   \n",
    "fullcols = fulldf.columns.tolist()\n",
    "\n",
    "newcols = ['Course','Description', 'Prerequisites', 'Source']\n",
    "\n",
    "whartondf = fulldf[newcols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stanford had problably the simplest, best-formatted website. Bless the people at Stanford who are running this website. \n",
    "\n",
    "source = 'https://exploredegrees.stanford.edu/graduateschoolofbusiness/#courseinventory'\n",
    "\n",
    "html = urlopen(str(source))\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#soup.find_all()\n",
    "title = soup.select('strong')\n",
    "\n",
    "for i in range(len(title)):\n",
    "    title[i] = re.sub('<[^<]+?>', '', str(title[i]))\n",
    "    \n",
    "titlelist = []\n",
    "desclist = []\n",
    "\n",
    "for i in soup.findAll('p'):\n",
    "    if str(i)[:28] == '<p class=\"courseblocktitle\">':\n",
    "        titlelist.append(i)\n",
    "    \n",
    "    elif str(i)[:27] == '<p class=\"courseblockdesc\">':\n",
    "        desclist.append(i)\n",
    "        \n",
    "        \n",
    "#Below is simply to remove html tags from the text.\n",
    "        \n",
    "for i in range(len(title)):\n",
    "    title[i] = re.sub('<[^<]+?>', '', str(title[i]))     \n",
    "    \n",
    "    \n",
    "\n",
    "stanforddf = pd.DataFrame(titlelist, columns=[\"Course\"])\n",
    "\n",
    "stanforddf['Description'] = desclist\n",
    "\n",
    "for i in range(len(stanforddf)):\n",
    "    stanforddf['Course'][i] = re.sub('<[^<]+?>', '', str( stanforddf['Course'][i]))\n",
    "    stanforddf['Description'][i] = re.sub('<[^<]+?>', '', str( stanforddf['Description'][i]))\n",
    "    \n",
    "\n",
    "\n",
    "stanforddf['Source'] = source\n",
    "\n",
    "for i in range(len(stanforddf)):\n",
    "    if i >0:\n",
    "        stanforddf['Source'][i]= ''\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will have to wait until I have a more finished product to test on. \n",
    "\n",
    "#import pdfkit\n",
    "\n",
    "#pdfkit.from_string(hbsdf, 'out.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In class, making notes for later. Can use .strip to remove whitespace. \n",
    "\n",
    "#look for class or id when you are doing .find_all as an argument within the function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
